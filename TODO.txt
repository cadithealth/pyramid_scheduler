* add support for::

    scheduler.add_cron_job(
      'import app ; app.get_singleton.run_method',
      ...
    )

  whose result should provide a callable. this to work around the fact
  that APS requires a global function... and maybe even declare
  centrally the set of values that should be in-scope... eg::

    schedule = Scheduler(eval_context=dict(
      MyGlobalApp1 = self,
      MyGlobalApp2 = lambda: get_my_global_app_2(),
    ))

  which would then allow::

    scheduler.add_cron_job(
      'MyGlobalApp.run_method',
      ...
    )

  or something similar

* perhaps catch APScheduler error:
    ValueError: Not adding job since it would never be run
  and, if within some "reasonable time" (configurable?), then run it *now*...
  (then delete all the TIMEPAD garbage)

* add new Events:
  - SCHEDULER_(STARTING|STARTED|STOPPING|STOPPED)
  - PRODUCER_(STARTING|STARTED|STOPPING|STOPPED)
  - CONSUMER_(STARTING|STARTED|STOPPING|STOPPED)
  ==> this would allow systems that need to ONLY run in the consumer
  to be started...

* create a pscheduler-install script:

  $ pscheduler-install \
      --service /etc/service/my-app-scheduler \
      --user www-data \
      --path /path/to/virtualenv/bin/pscheduler \
      --log /var/log/pscheduler-my-app \
      --log-max 1GB \
      --log-count 10 \
      --env {KEY}={VALUE} \
      /path/to/config.ini

   - check that 'multilog' and 'setuigid' are in PATH
   - maybe wait a second and ensure that both 'supervise' directories show up?

* generate API documentation with sphinx
* if pyramid_exclog is installed, make use of it
* make the sqlalchemy kombu driver clean up old messages
* make kombu sqlalchemy backend use a provided session and not auto-commit
* make kombu sqlalchemy backend, if psycopg2 engine, use LISTEN/NOTIFY
* submit a patch to APS that allows them to use non-naive datetime objects
* review all of the "limitations", and either fix them, or detect and raise:
  * do a round-trip test of the callback handler to ensure that it is loadable
  * do not silently drop jobs...
  * check that all datetime objects are 'naive'... can they be auto-corrected?...
* make the Job table by default also have the "unwrapped" function name in the
  columns (so that the extra "job_type" added in cadit/canary is not needed)
* "cron" style jobs...
  * document it better
  * figure out how to make it (optionally) UTC based?

* BUG: getting this in the pscheduler log files:

@40000000547d2b4b1e478c7c Traceback (most recent call last):
@40000000547d2b4b1e479064   File "/usr/lib/python2.7/threading.py", line 551, in __bootstrap_inner
@40000000547d2b4b1e479064   File "/usr/lib/python2.7/threading.py", line 504, in run
@40000000547d2b4b1e479064   File "/var/virtualenv/local/lib/python2.7/site-packages/apscheduler/scheduler.py", line 577, in _main_loop
@40000000547d2b4b1e47944c <type 'exceptions.AttributeError'>: 'NoneType' object has no attribute 'debug'
